"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[2517],{8453:(t,o,n)=>{n.d(o,{R:()=>s,x:()=>c});var e=n(6540);const i={},a=e.createContext(i);function s(t){const o=e.useContext(a);return e.useMemo(function(){return"function"==typeof t?t(o):{...o,...t}},[o,t])}function c(t){let o;return o=t.disableParentContext?"function"==typeof t.components?t.components(i):t.components||i:s(t.components),e.createElement(a.Provider,{value:o},t.children)}},9521:(t,o,n)=>{n.r(o),n.d(o,{assets:()=>l,contentTitle:()=>c,default:()=>u,frontMatter:()=>s,metadata:()=>e,toc:()=>d});const e=JSON.parse('{"id":"module-4/multi-modal","title":"Multi-Modal Integration: Combining Vision, Language, and Action","description":"This chapter covers combining vision, language, and action systems to create a cohesive multi-modal robotics system.","source":"@site/docs/module-4/05-multi-modal.md","sourceDirName":"module-4","slug":"/module-4/multi-modal","permalink":"/Physical-AI---Humanoid-Robotics/docs/module-4/multi-modal","draft":false,"unlisted":false,"editUrl":"https://github.com/abdullahnisar05/Physical-AI---Humanoid-Robotics/edit/main/website/docs/module-4/05-multi-modal.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Bridging Language to Action: Parsing LLM Output into Executable Robot Commands","permalink":"/Physical-AI---Humanoid-Robotics/docs/module-4/language-to-action"},"next":{"title":"Capstone Project: Building the Autonomous Humanoid (Full End-to-End Guide)","permalink":"/Physical-AI---Humanoid-Robotics/docs/module-4/capstone"}}');var i=n(4848),a=n(8453);const s={sidebar_position:5},c="Multi-Modal Integration: Combining Vision, Language, and Action",l={},d=[];function r(t){const o={h1:"h1",header:"header",p:"p",...(0,a.R)(),...t.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(o.header,{children:(0,i.jsx)(o.h1,{id:"multi-modal-integration-combining-vision-language-and-action",children:"Multi-Modal Integration: Combining Vision, Language, and Action"})}),"\n",(0,i.jsx)(o.p,{children:"This chapter covers combining vision, language, and action systems to create a cohesive multi-modal robotics system."})]})}function u(t={}){const{wrapper:o}={...(0,a.R)(),...t.components};return o?(0,i.jsx)(o,{...t,children:(0,i.jsx)(r,{...t})}):r(t)}}}]);