"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[2517],{8453:(o,t,n)=>{n.d(t,{R:()=>s,x:()=>c});var e=n(6540);const i={},a=e.createContext(i);function s(o){const t=e.useContext(a);return e.useMemo(function(){return"function"==typeof o?o(t):{...t,...o}},[t,o])}function c(o){let t;return t=o.disableParentContext?"function"==typeof o.components?o.components(i):o.components||i:s(o.components),e.createElement(a.Provider,{value:t},o.children)}},9521:(o,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>s,metadata:()=>e,toc:()=>l});const e=JSON.parse('{"id":"module-4/multi-modal","title":"Multi-Modal Integration: Combining Vision, Language, and Action","description":"This chapter covers combining vision, language, and action systems to create a cohesive multi-modal robotics system.","source":"@site/docs/module-4/05-multi-modal.md","sourceDirName":"module-4","slug":"/module-4/multi-modal","permalink":"/Physical-AI---Humanoid-Robotics/docs/module-4/multi-modal","draft":false,"unlisted":false,"editUrl":"https://github.com/Physical-AI-Humanoid-Robotics/book/edit/main/website/docs/module-4/05-multi-modal.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Bridging Language to Action: Parsing LLM Output into Executable Robot Commands","permalink":"/Physical-AI---Humanoid-Robotics/docs/module-4/language-to-action"},"next":{"title":"Capstone Project: Building the Autonomous Humanoid (Full End-to-End Guide)","permalink":"/Physical-AI---Humanoid-Robotics/docs/module-4/capstone"}}');var i=n(4848),a=n(8453);const s={sidebar_position:5},c="Multi-Modal Integration: Combining Vision, Language, and Action",d={},l=[];function r(o){const t={h1:"h1",header:"header",p:"p",...(0,a.R)(),...o.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"multi-modal-integration-combining-vision-language-and-action",children:"Multi-Modal Integration: Combining Vision, Language, and Action"})}),"\n",(0,i.jsx)(t.p,{children:"This chapter covers combining vision, language, and action systems to create a cohesive multi-modal robotics system."})]})}function u(o={}){const{wrapper:t}={...(0,a.R)(),...o.components};return t?(0,i.jsx)(t,{...o,children:(0,i.jsx)(r,{...o})}):r(o)}}}]);